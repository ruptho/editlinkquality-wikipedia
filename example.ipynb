{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Example Computation Pipeline\n",
    "## for results presented in \"On the Relation of Edit Behavior, Link Structure, and Article Quality on Wikipedia\" by Thorsten Ruprechter, Tiago Santos, and Denis Helic\n",
    "\n",
    "### Import statements and assignment of frequently used variables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import editbehavior as eb\n",
    "import linkstructure as ls\n",
    "import stats\n",
    "import utils\n",
    "\n",
    "data_dir = 'data'\n",
    "article_dir = 'data/articles'\n",
    "article_folders = ['a', 'b', 'c', 'featured', 'good', 'cw']\n",
    "labels = ['Content', 'Format', 'WikiContext']\n",
    "label_combinations = eb.get_label_combinations(labels)[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load Results of External Frameworks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load features and labels as processed by Yang et al.'s framework here (e.g., from pickle file)\n",
    "# Necessary for computation of edit label metrics\n",
    "features, y_labels = utils.load_from_file_pickle('<Filename for Features>', data_dir)\n",
    "\n",
    "# Load (and postprocess, if required) WikiLinkGraphs dataset\n",
    "# Necessary for link metric computation\n",
    "# Note the optional postprocessing: resolve Wikipedia redirects and remove redirects (nodes with single outgoing link).\n",
    "# If no processing is needed for the current task, one could also directly load the WikiLinkGraphs dataset.\n",
    "# The example uses csv's, but files could be of any type.\n",
    "wikilinkgraphs = ls.resolve_redirects(\n",
    "        utils.read_csv('<Filename for Wikipedia redirects>.csv', data_dir, escape=csv.QUOTE_ALL),\n",
    "        utils.read_csv('<Filename for WikiLinkGraphs>.csv', data_dir, delimiter='\\t'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculating Relative Frequencies and Transition Probabilities for Edit Actions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train random forest on given data\n",
    "random_forest = eb.train_random_forest(features, y_labels)\n",
    "\n",
    "# for this example, we store our articles in separate folders\n",
    "category_dict = {}\n",
    "for cat_folder in article_folders:\n",
    "    # this could be any article list you like\n",
    "    articles = utils.get_article_files_pickle(utils.get_path(article_dir, cat_folder))\n",
    "    labeled_articles = eb.label_article_folder(random_forest, articles, cat_folder, article_dir)\n",
    "    category_dict[cat_folder] = labeled_articles\n",
    "\n",
    "# Compute transition probabilities and relative frequencies\n",
    "tp_articles, tp_categories = eb.calculate_transition_probabilities(category_dict, labels)\n",
    "rf_articles, rf_categories = eb.calculate_relative_frequencies(category_dict)\n",
    "\n",
    "# Option to calculate revision info (articles, revs/article, etc.) as well as macro and micro results for categories\n",
    "cat_revcount, rf_cat_macro, rf_cat_micro = eb.get_micro_and_macro_arrays(rf_categories, label_combinations)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Permutation Tests for Relative Frequencies and Transition Probabilities"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tp_sig = stats.permutation_test(tp_articles)\n",
    "rf_sig = stats.permutation_test_frequency(rf_articles, label_combinations)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Link Analysis of WikiLinkGraphs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Build graph\n",
    "G = ls.build_graph_from_wikilinkgraphs(wikilinkgraphs)\n",
    "\n",
    "# Specify which articles belong to which category - depends on current task\n",
    "articles_per_category = None  # can also just use previous results as we do here\n",
    "\n",
    "# Calculate metric (e.g., out-degree)\n",
    "out_degree_dict = {utils.normalize_article(k): deg for k, deg in G.out_degree().items()}\n",
    "\n",
    "# Use helper to pick apart article results per category\n",
    "# This step returns the outdegrees per category, in nested arrays.\n",
    "categories, outdegree_per_cat, not_found = ls.order_metric_by_category(out_degree_dict, articles_per_category)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}